# Анализ проблемы и решения

## Контекст
Задача: Заставить работать пайплайн ProPainter на сервере с RTX 4080 и CUDA 12+. Исходная проблема: RAFT падает с CUDA error из-за несовместимости кастомного ядра `alt_cuda_corr`. Решение: отключить `alt_cuda_corr` и использовать PyTorch-реализацию корреляции.

## Проблемы, с которыми столкнулись

### 1. Ошибка CUDA в RAFT
- **Симптом**: `CUDA error: CUBLAS_STATUS_INVALID_VALUE` при вызове `cublasGemmEx` или `cublasSgemmStridedBatched`.
- **Причина**: Несовместимость библиотек CUDA, драйверов или архитектуры GPU с кастомным ядром `alt_cuda_corr`.
- **Решение**: Патч файла `RAFT/corr.py`:
  - Заменить блок импорта `alt_cuda_corr` на принудительное отключение (`alt_cuda_corr = None`).
  - Добавить безопасное умножение матриц с приведением к FP32 и contiguous memory layout.

### 2. Ошибка shape в inference_core.py
- **Симптом**: `shape '[1, X, 2, 284, 160]' is invalid for input of size Y` или `index out of bounds`.
- **Причина**: Модель ожидает потоки (optical flow) только для `LOCAL_FRAMES-1` кадров, но передавались все потоки (для N-1 кадров). Также модель возвращает предсказания только для `LOCAL_FRAMES` кадров, а не для всех кадров.
- **Решение**: 
  - Обрезать потоки `fwd_flow` и `bwd_flow` до `LOCAL_FRAMES-1`.
  - Установить `LOCAL_FRAMES` равным общему количеству кадров (`original_length`), чтобы модель обрабатывала все кадры за один проход.

### 3. Ошибка CUBLAS на GPU даже после отключения alt_cuda_corr
- **Симптом**: Та же ошибка `CUBLAS_STATUS_INVALID_VALUE` при использовании FP16 (half precision) или FP32 с включённым TF32.
- **Причина**: Возможная несовместимость версий CUDA, cuBLAS, PyTorch или драйверов. Также возможно, что модель содержит операции, которые не поддерживаются на данной архитектуре GPU (RTX 4080, compute capability 8.9) с текущими настройками.
- **Решение**: Переключение на CPU режим гарантирует стабильность, хотя и медленнее.

## Что было сделано

### 1. Патч RAFT/corr.py
Файл `/opt/ProPainter-Wire/RAFT/corr.py` изменён:
- Заменён блок импорта `alt_cuda_corr` на принудительное отключение.
- Добавлено безопасное умножение матриц с приведением к FP32 и contiguous memory layout.

### 2. Модификация inference_core.py
Файл `/opt/ProPainter-Wire/inference_core.py` прошёл несколько итераций:

**Версия 1 (GPU + FP16)**:
- Использование `.half()` для модели и тензоров.
- Ошибка CUBLAS.

**Версия 2 (GPU + FP32)**:
- Переход на `.float()`.
- Ошибка CUBLAS осталась.

**Версия 3 (GPU + FP32 + обрезка потоков)**:
- Добавлена обрезка потоков до `LOCAL_FRAMES-1`.
- Ошибка CUBLAS осталась.

**Версия 4 (CPU + FP32)**:
- Принудительное использование `device = torch.device("cpu")`.
- Установка `LOCAL_FRAMES = original_length`.
- Обрезка потоков.
- **Успех**: пайплайн завершился без ошибок, выходные файлы созданы.

### 3. Коммиты и синхронизация
Все изменения закоммичены в репозиторий и вытянуты на сервер.

## Как работает текущее решение

### Алгоритм пайплайна (CPU режим)
1. **Загрузка данных**: Чтение кадров и масок из директорий.
2. **Предобработка**: Масштабирование до безопасного разрешения (640p), паддинг до кратности 16.
3. **Вычисление оптического потока**: Используется OpenCV Farneback на CPU (downscale 0.5 для скорости).
4. **Подготовка тензоров**: Все тензоры в FP32 на CPU.
5. **Инференс модели**: Модель `InpaintGenerator` получает:
   - `frames_tensor`: [1, T, C, H, W]
   - `flows`: (fwd_trim, bwd_trim) где каждый [1, T-1, 2, H, W]
   - `masks_tensor`: [1, T, 1, H, W]
   - `LOCAL_FRAMES = T` (все кадры как локальное окно)
6. **Сохранение результатов**: Наложение предсказания на оригинальные кадры с использованием маски, сохранение в выходную директорию.

### Ключевые параметры
- `SAFE_SIDE = 640` – безопасное разрешение для CPU.
- `MIN_FRAMES = 8` – минимальное количество кадров для паддинга.
- `LOCAL_FRAMES = original_length` – количество кадров, обрабатываемых за один проход.
- `downscale_factor = 0.5` – масштаб для вычисления оптического потока.

## Почему не работает на GPU: предположения

### 1. Несовместимость библиотек
- Версия CUDA Toolkit (12.4) может быть несовместима с версией PyTorch (2.5.1) или cuDNN.
- Драйвер NVIDIA (555.42) может иметь баги с операциями gemm для определённых размерностей.

### 2. Проблемы с half precision (FP16)
- Ошибка `CUBLAS_STATUS_INVALID_VALUE` при использовании FP16 указывает на неподдерживаемые размеры или форматы данных.
- Возможно, некоторые тензоры имеют страйды или выравнивание, которые cuBLAS не может обработать.

### 3. Ограничения архитектуры RTX 4080
- Compute capability 8.9 может требовать особых флагов компиляции для кастомных ядер, которые отсутствуют.

### 4. Ошибка в модели Sparse Transformer
- Модель использует кастомные операции (например, sparse attention), которые могут вызывать ошибки CUDA при определённых условиях.

## Что нужно для работы на GPU: требования

### 1. Совместимость версий
- PyTorch 2.5.1 + CUDA 12.4 + cuDNN 8.9 + драйвер NVIDIA >= 555.
- Проверить совместимость через `torch.cuda.is_available()` и `torch.cuda.get_device_capability()`.

### 2. Настройки precision
- Использовать FP32 (`.float()`) для всех тензоров.
- Отключить TF32: `torch.backends.cuda.matmul.allow_tf32 = False`.
- Убедиться, что все тензоры contiguous: `.contiguous()` перед операциями.

### 3. Размерности данных
- Количество кадров `T` должно быть >= `LOCAL_FRAMES`.
- Потоки должны быть обрезаны до `LOCAL_FRAMES-1`.
- Разрешение должно быть кратным 16.

### 4. Окружение
- Установить переменные окружения:
  ```bash
  export CUDA_LAUNCH_BLOCKING=1
  export CUDA_VISIBLE_DEVICES=0
  ```
- Использовать `torch.backends.cuda.sdp_kernel(enable_flash=False, enable_math=True, enable_mem_efficient=False)`.

## Пути к скриптам и инструкции

### Основные файлы
- `/opt/ProPainter-Wire/inference_core.py` – главный скрипт инференса.
- `/opt/ProPainter-Wire/RAFT/corr.py` – патченный модуль корреляции.
- `/opt/ProPainter-Wire/model/propainter.py` – модель ProPainter.
- `/opt/ProPainter-Wire/weights/ProPainter.pth` – веса модели.

### Запуск пайплайна (CPU)
```bash
cd /opt/ProPainter-Wire
python3 inference_core.py \
  --video /path/to/frames \
  --mask /path/to/masks \
  --output /path/to/output \
  --model_path weights/ProPainter.pth
```

### Запуск пайплайна (GPU – экспериментальный)
```bash
cd /opt/ProPainter-Wire
# Убедиться, что inference_core.py использует device='cuda' и float()
python3 inference_core.py \
  --video /path/to/frames \
  --mask /path/to/masks \
  --output /path/to/output \
  --model_path weights/ProPainter.pth
```

### Отладка
1. **Включить детальный вывод**: Добавить `print` в ключевых местах, использовать `torch.cuda.synchronize()`.
2. **Проверить тензоры**: Убедиться, что размерности, dtype и device соответствуют ожиданиям.
3. **Использовать CUDA_LAUNCH_BLOCKING**: Для синхронного выполнения и точного определения места ошибки.
4. **Профилирование**: Использовать `torch.profiler` или `nvprof` для анализа операций CUDA.

## Предложения для дальнейшего исследования

### 1. Диагностика CUDA
- Запустить тесты PyTorch CUDA: `python -c "import torch; torch.cuda.test()"`.
- Проверить версии: `torch.__version__`, `torch.version.cuda`.
- Сравнить с официальной матрицей совместимости PyTorch.

### 2. Анализ ошибки CUBLAS
- Уменьшить размер данных (меньше кадров, меньше разрешение) для локализации проблемы.
- Попробовать разные комбинации precision (FP32, TF32, FP16).
- Использовать `torch.backends.cuda.matmul.allow_tf32 = True/False`.

### 3. Альтернативные реализации
- Заменить оптический поток RAFT на другой метод (например, PWC-Net).
- Использовать оптимизированную версию Sparse Transformer (`sparse_transformer_optimized.py`).

### 4. Обновление окружения
- Обновить PyTorch до последней версии с поддержкой CUDA 12.4.
- Пересобрать `alt_cuda_corr` с правильными флагами для RTX 4080.

### 5. Фоллбэк на CPU
- Если GPU нестабилен, использовать CPU для продакшена с оптимизацией (например, OpenMP, batch processing).

## Заключение
Текущее решение стабильно работает на CPU и может быть использовано для выполнения задач. Для GPU требуется дополнительная диагностика и, возможно, обновление библиотек или модификация кода. Рекомендуется вести лог всех экспериментов и ошибок для системного анализа.
